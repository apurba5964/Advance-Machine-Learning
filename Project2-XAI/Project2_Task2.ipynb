{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "yHtgqtQQax3I",
    "outputId": "c62b9745-7993-4d79-b97e-ea31b43a176e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pgmpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/08/e4133e10117f01b966ce4f89b13bcb423115466434f6fd32a9cf437412c3/pgmpy-0.1.7-py3-none-any.whl (288kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 15.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from pgmpy) (1.14.6)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pgmpy) (1.1.0)\n",
      "Collecting networkx<1.12,>=1.11 (from pgmpy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/2c/e473e54afc9fae58dfa97066ef6709a7e35a1dd1c28c5a3842989322be00/networkx-1.11-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 18.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from networkx<1.12,>=1.11->pgmpy) (4.4.0)\n",
      "\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
      "\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
      "Installing collected packages: networkx, pgmpy\n",
      "  Found existing installation: networkx 2.2\n",
      "    Uninstalling networkx-2.2:\n",
      "      Successfully uninstalled networkx-2.2\n",
      "Successfully installed networkx-1.11 pgmpy-0.1.7\n"
     ]
    }
   ],
   "source": [
    "#!pip install pgmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f1F0oIVIa21q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.estimators import HillClimbSearch\n",
    "from pgmpy.estimators import K2Score\n",
    "from pgmpy.models.BayesianModel import BayesianModel\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iAmLsSWwbCht"
   },
   "outputs": [],
   "source": [
    "seen_data = \"seen-dataset/dataset_seen_training_siamese.csv\"\n",
    "seen_validation_data = \"seen-dataset/dataset_seen_validation_siamese.csv\"\n",
    "shuffled_data = \"shuffled-dataset/dataset_seen_training_siamese.csv\"\n",
    "shuffled_validation_data = \"shuffled-dataset/dataset_seen_validation_siamese.csv\"\n",
    "unseen_data = \"unseen-dataset/dataset_seen_training_siamese.csv\"\n",
    "unseen_validation_data = \"unseen-dataset/dataset_seen_validation_siamese.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kV2yjL6ZbIxw"
   },
   "outputs": [],
   "source": [
    "andTable1 = pd.read_csv(\"15features.csv\")\n",
    "andTable2 = pd.read_csv(\"15features.csv\")\n",
    "leftAndTable = andTable1.iloc[:,1:]\n",
    "rightAndTable = andTable2.iloc[:,1:]\n",
    "\n",
    "for i in range(0,len(leftAndTable.columns.values)):\n",
    "    leftAndTable.columns.values[i] = 'left_'+ leftAndTable.columns.values[i] \n",
    "\n",
    "for i in range(0,len(rightAndTable.columns.values)):\n",
    "    rightAndTable.columns.values[i] = 'right_'+ rightAndTable.columns.values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "PGhy2_mjbo8p",
    "outputId": "fe4ae93b-74c5-46df-b0d0-299990dd722a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('left_pen_pressure', 'left_is_lowercase'), ('left_pen_pressure', 'left_letter_spacing'), ('left_size', 'left_slantness'), ('left_size', 'left_pen_pressure'), ('left_size', 'left_staff_of_d'), ('left_size', 'left_letter_spacing'), ('left_size', 'left_exit_stroke_d'), ('left_size', 'left_entry_stroke_a'), ('left_dimension', 'left_size'), ('left_dimension', 'left_is_continuous'), ('left_dimension', 'left_slantness'), ('left_dimension', 'left_pen_pressure'), ('left_is_lowercase', 'left_staff_of_a'), ('left_is_lowercase', 'left_exit_stroke_d'), ('left_is_continuous', 'left_exit_stroke_d'), ('left_is_continuous', 'left_letter_spacing'), ('left_is_continuous', 'left_entry_stroke_a'), ('left_is_continuous', 'left_staff_of_a'), ('left_is_continuous', 'left_is_lowercase'), ('left_slantness', 'left_is_continuous'), ('left_slantness', 'left_tilt'), ('left_entry_stroke_a', 'left_pen_pressure'), ('left_formation_n', 'left_constancy'), ('left_formation_n', 'left_word_formation'), ('left_formation_n', 'left_dimension'), ('left_formation_n', 'left_staff_of_d'), ('left_formation_n', 'left_is_continuous'), ('left_formation_n', 'left_size'), ('left_formation_n', 'left_staff_of_a'), ('left_staff_of_d', 'left_is_continuous'), ('left_staff_of_d', 'left_exit_stroke_d'), ('left_staff_of_d', 'left_is_lowercase'), ('left_staff_of_d', 'left_slantness'), ('left_staff_of_d', 'left_entry_stroke_a'), ('left_word_formation', 'left_dimension'), ('left_word_formation', 'left_staff_of_a'), ('left_word_formation', 'left_size'), ('left_word_formation', 'left_staff_of_d'), ('left_word_formation', 'left_constancy'), ('left_constancy', 'left_staff_of_a'), ('left_constancy', 'left_letter_spacing'), ('left_constancy', 'left_dimension')]\n",
      "-139940.6025016286\n"
     ]
    }
   ],
   "source": [
    "hc = HillClimbSearch(leftAndTable, scoring_method=K2Score(leftAndTable))\n",
    "left_model = hc.estimate()\n",
    "print(left_model.edges())\n",
    "\n",
    "k2= K2Score(leftAndTable)\n",
    "print(k2.score(left_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "b632n2wQbuTh",
    "outputId": "b4a080d7-41ba-42c7-d4ef-9f7c6ad54a6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('right_pen_pressure', 'right_is_lowercase'), ('right_pen_pressure', 'right_letter_spacing'), ('right_size', 'right_slantness'), ('right_size', 'right_pen_pressure'), ('right_size', 'right_staff_of_d'), ('right_size', 'right_letter_spacing'), ('right_size', 'right_exit_stroke_d'), ('right_size', 'right_entry_stroke_a'), ('right_dimension', 'right_size'), ('right_dimension', 'right_is_continuous'), ('right_dimension', 'right_slantness'), ('right_dimension', 'right_pen_pressure'), ('right_is_lowercase', 'right_staff_of_a'), ('right_is_lowercase', 'right_exit_stroke_d'), ('right_is_continuous', 'right_exit_stroke_d'), ('right_is_continuous', 'right_letter_spacing'), ('right_is_continuous', 'right_entry_stroke_a'), ('right_is_continuous', 'right_staff_of_a'), ('right_is_continuous', 'right_is_lowercase'), ('right_slantness', 'right_is_continuous'), ('right_slantness', 'right_tilt'), ('right_entry_stroke_a', 'right_pen_pressure'), ('right_formation_n', 'right_constancy'), ('right_formation_n', 'right_word_formation'), ('right_formation_n', 'right_dimension'), ('right_formation_n', 'right_staff_of_d'), ('right_formation_n', 'right_is_continuous'), ('right_formation_n', 'right_size'), ('right_formation_n', 'right_staff_of_a'), ('right_staff_of_d', 'right_is_continuous'), ('right_staff_of_d', 'right_exit_stroke_d'), ('right_staff_of_d', 'right_is_lowercase'), ('right_staff_of_d', 'right_slantness'), ('right_staff_of_d', 'right_entry_stroke_a'), ('right_word_formation', 'right_dimension'), ('right_word_formation', 'right_staff_of_a'), ('right_word_formation', 'right_size'), ('right_word_formation', 'right_staff_of_d'), ('right_word_formation', 'right_constancy'), ('right_constancy', 'right_staff_of_a'), ('right_constancy', 'right_letter_spacing'), ('right_constancy', 'right_dimension')]\n",
      "-139940.6025016286\n"
     ]
    }
   ],
   "source": [
    "hc = HillClimbSearch(rightAndTable, scoring_method=K2Score(rightAndTable))\n",
    "right_model = hc.estimate()\n",
    "print(right_model.edges())\n",
    "\n",
    "k2= K2Score(rightAndTable)\n",
    "print(k2.score(right_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MeMVhNBdLXB"
   },
   "outputs": [],
   "source": [
    "def getNewBayesianModel():\n",
    "    newBayesianModel = BayesianModel([('left_pen_pressure', 'left_is_lowercase'), ('left_pen_pressure', 'left_letter_spacing'), \n",
    "                                  ('left_size', 'left_slantness'), ('left_size', 'left_pen_pressure'), ('left_size', 'left_staff_of_d'), \n",
    "                                  ('left_size', 'left_letter_spacing'), ('left_size', 'left_exit_stroke_d'), ('left_size', 'left_entry_stroke_a'), \n",
    "                                  ('left_dimension', 'left_size'), ('left_dimension', 'left_is_continuous'), ('left_dimension', 'left_slantness'), \n",
    "                                  ('left_dimension', 'left_pen_pressure'), ('left_is_lowercase', 'left_staff_of_a'), \n",
    "                                  ('left_is_lowercase', 'left_exit_stroke_d'), ('left_is_continuous', 'left_exit_stroke_d'),\n",
    "                                  ('left_is_continuous', 'left_letter_spacing'), ('left_is_continuous', 'left_entry_stroke_a'), \n",
    "                                  ('left_is_continuous', 'left_staff_of_a'),\n",
    "                                  ('left_is_continuous', 'left_is_lowercase'), ('left_slantness', 'left_is_continuous'),\n",
    "                                  ('left_slantness', 'left_tilt'), ('left_entry_stroke_a', 'left_pen_pressure'), \n",
    "                                  ('left_formation_n', 'left_constancy'), ('left_formation_n', 'left_word_formation'),\n",
    "                                  ('left_formation_n', 'left_dimension'), ('left_formation_n', 'left_staff_of_d'),\n",
    "                                  ('left_formation_n', 'left_is_continuous'), ('left_formation_n', 'left_size'), \n",
    "                                  ('left_formation_n', 'left_staff_of_a'), ('left_staff_of_d', 'left_is_continuous'), \n",
    "                                  ('left_staff_of_d', 'left_exit_stroke_d'), ('left_staff_of_d', 'left_is_lowercase'), \n",
    "                                  ('left_staff_of_d', 'left_slantness'), ('left_staff_of_d', 'left_entry_stroke_a'), \n",
    "                                  ('left_word_formation', 'left_dimension'), ('left_word_formation', 'left_staff_of_a'), \n",
    "                                  ('left_word_formation', 'left_size'), ('left_word_formation', 'left_staff_of_d'), \n",
    "                                  ('left_word_formation', 'left_constancy'), ('left_constancy', 'left_staff_of_a'), \n",
    "                                  ('left_constancy', 'left_letter_spacing'), ('left_constancy', 'left_dimension'),\n",
    "                                 ('right_pen_pressure', 'right_is_lowercase'), ('right_pen_pressure', 'right_letter_spacing'), ('right_size', 'right_slantness'), ('right_size', 'right_pen_pressure'), ('right_size', 'right_staff_of_d'), ('right_size', 'right_letter_spacing'), ('right_size', 'right_exit_stroke_d'), ('right_size', 'right_entry_stroke_a'), ('right_dimension', 'right_size'), ('right_dimension', 'right_is_continuous'), ('right_dimension', 'right_slantness'), ('right_dimension', 'right_pen_pressure'), ('right_is_lowercase', 'right_staff_of_a'), ('right_is_lowercase', 'right_exit_stroke_d'), ('right_is_continuous', 'right_exit_stroke_d'), ('right_is_continuous', 'right_letter_spacing'), ('right_is_continuous', 'right_entry_stroke_a'), ('right_is_continuous', 'right_staff_of_a'), ('right_is_continuous', 'right_is_lowercase'), ('right_slantness', 'right_is_continuous'), ('right_slantness', 'right_tilt'), ('right_entry_stroke_a', 'right_pen_pressure'), ('right_formation_n', 'right_constancy'), ('right_formation_n', 'right_word_formation'), ('right_formation_n', 'right_dimension'), ('right_formation_n', 'right_staff_of_d'), ('right_formation_n', 'right_is_continuous'), ('right_formation_n', 'right_size'), ('right_formation_n', 'right_staff_of_a'), ('right_staff_of_d', 'right_is_continuous'), ('right_staff_of_d', 'right_exit_stroke_d'), ('right_staff_of_d', 'right_is_lowercase'), ('right_staff_of_d', 'right_slantness'), ('right_staff_of_d', 'right_entry_stroke_a'), ('right_word_formation', 'right_dimension'), ('right_word_formation', 'right_staff_of_a'), ('right_word_formation', 'right_size'), ('right_word_formation', 'right_staff_of_d'), ('right_word_formation', 'right_constancy'), ('right_constancy', 'right_staff_of_a'), ('right_constancy', 'right_letter_spacing'),\n",
    "                                  ('right_constancy', 'right_dimension'),('right_dimension', 'label'),\n",
    "                                 ('left_dimension', 'label'),('left_pen_pressure', 'label'),\n",
    "                                 ('right_pen_pressure', 'label')])\n",
    "    return newBayesianModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XAUHRl6hfRMs"
   },
   "outputs": [],
   "source": [
    "def generateData(dataset):\n",
    "    \n",
    "    sameDiffPair = pd.read_csv(dataset)\n",
    "    sameDiffPair = sameDiffPair.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    samePair = sameDiffPair.loc[sameDiffPair['label'] == 1].reset_index(drop=True)\n",
    "    diffPair = sameDiffPair.loc[sameDiffPair['label'] == 0].reset_index(drop=True)\n",
    "\n",
    "    #print(samePair.shape) \n",
    "    #print(diffPair.shape)\n",
    "    merged1 = pd.merge(samePair, andTable1, left_on = ['left'],right_on= ['imagename'],how = 'left').drop(['imagename'], axis='columns')\n",
    "    merged2 = pd.merge(samePair, andTable2, left_on = ['right'],right_on= ['imagename'],how = 'left').drop(['imagename','left','right','label'],axis='columns')\n",
    "    merged3=pd.concat([merged1, merged2],axis=1)\n",
    "    merged3= merged3.drop(['left','right'], axis='columns')\n",
    "    merged4 = pd.merge(diffPair, andTable1, left_on = ['left'],right_on= ['imagename'],how = 'left').drop(['imagename'], axis='columns')\n",
    "    merged5 = pd.merge(diffPair, andTable2, left_on = ['right'],right_on= ['imagename'],how = 'left').drop(['imagename','left','right','label'],axis='columns')\n",
    "    merged6=pd.concat([merged4, merged5],axis=1)\n",
    "    merged6= merged6.drop(['left','right'], axis='columns')\n",
    "    concatFeatures=pd.concat([merged3,merged6],axis = 0) \n",
    "    \n",
    "    concatFeatures = concatFeatures.dropna()\n",
    "    print(concatFeatures.shape)\n",
    "    concatFeatures=shuffle(concatFeatures)\n",
    "    return concatFeatures\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "2OY-sQbQfVtC",
    "outputId": "277fb660-2098-4504-8fd6-97017462cf7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111753, 31)\n",
      "(894, 31)\n",
      "(99825, 31)\n",
      "(5240, 31)\n",
      "(127273, 31)\n",
      "(7221, 31)\n"
     ]
    }
   ],
   "source": [
    "training_seen_features = generateData(seen_data).reset_index(drop=True)\n",
    "validation_seen_features = generateData(seen_validation_data).reset_index(drop=True)\n",
    "\n",
    "training_shuffled_features = generateData(shuffled_data).reset_index(drop=True)\n",
    "validation_shuffled_features = generateData(shuffled_validation_data).reset_index(drop=True)\n",
    "\n",
    "\n",
    "training_unseen_features = generateData(unseen_data).reset_index(drop=True)\n",
    "validation_unseen_features = generateData(unseen_validation_data).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XB_wE2G2fka2"
   },
   "outputs": [],
   "source": [
    "def normalizeData(data_feature):\n",
    "    columns=data_feature.columns\n",
    "    len(columns)\n",
    "    for i in range(1,len(columns)):\n",
    "        data_feature[columns[i]]=data_feature[columns[i]]-1\n",
    "    \n",
    "    return data_feature\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMRxHKmzhgrN"
   },
   "outputs": [],
   "source": [
    "normalized_training_seen_features = normalizeData(training_seen_features)\n",
    "normalized_validation_seen_features = normalizeData(validation_seen_features)\n",
    "validation_seen_target_vector = normalized_validation_seen_features['label']\n",
    "validation_seen_data_vector = normalized_validation_seen_features.iloc[:,1:]\n",
    "validation_seen_data_vector = validation_seen_data_vector.astype(int)\n",
    "seenValidationDict = validation_seen_data_vector.to_dict('index')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "normalized_training_shuffled_features = normalizeData(training_shuffled_features)\n",
    "normalized_validation_shuffled_features = normalizeData(validation_shuffled_features)\n",
    "validation_shuffled_target_vector = normalized_validation_shuffled_features['label']\n",
    "validation_shuffled_data_vector = normalized_validation_shuffled_features.iloc[:,1:]\n",
    "validation_shuffled_data_vector = validation_shuffled_data_vector.astype(int)\n",
    "shuffledValidationDict = validation_shuffled_data_vector.to_dict('index')\n",
    "\n",
    "\n",
    "normalized_training_unseen_features = normalizeData(training_unseen_features)\n",
    "normalized_validation_unseen_features = normalizeData(validation_unseen_features)\n",
    "validation_unseen_target_vector = normalized_validation_unseen_features['label']\n",
    "validation_unseen_data_vector = normalized_validation_unseen_features.iloc[:,1:]\n",
    "validation_unseen_data_vector = validation_unseen_data_vector.astype(int)\n",
    "unseenValidationDict = validation_unseen_data_vector.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlOrFjYqhkGD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "plSGvViuhs44",
    "outputId": "133df16b-e808-44a1-f91e-1844c2fd67f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Model Number of edges: 88\n",
      "Seen Dataset time to trainin sec: 3.011582612991333\n",
      "Shuffled Dataset time to train in sec: 2.870882034301758\n",
      "Unseen Dataset time to train in sec: 3.542854070663452\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "seenBayesianModel = getNewBayesianModel()\n",
    "print(\"Bayesian Model Number of edges: \" + str(len(seenBayesianModel.edges())))\n",
    "seenBayesianModel.fit(normalized_training_seen_features)\n",
    "end = time.time()\n",
    "print(\"Seen Dataset time to trainin sec: \" + str(end-start))\n",
    "\n",
    "start = time.time()\n",
    "shuffledBayesianModel = getNewBayesianModel()\n",
    "shuffledBayesianModel.fit(normalized_training_shuffled_features)\n",
    "end = time.time()\n",
    "print(\"Shuffled Dataset time to train in sec: \" + str(end-start))\n",
    "\n",
    "start = time.time()\n",
    "unseenBayesianModel = getNewBayesianModel()\n",
    "unseenBayesianModel.fit(normalized_training_unseen_features)\n",
    "end = time.time()\n",
    "print(\"Unseen Dataset time to train in sec: \" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YX8OcDw5h9GJ"
   },
   "outputs": [],
   "source": [
    "from pgmpy.inference import VariableElimination\n",
    "def getValidationAccuracy(target_vector,dataDict,model):\n",
    "    infer = VariableElimination(model)\n",
    "    count = 0\n",
    "    for i in range(0,len(target_vector)):\n",
    "        data = dataDict[i]\n",
    "        target = target_vector[i]\n",
    "        #print(dataDict)\n",
    "        predicted = infer.map_query(['label'], evidence=data) ['label']\n",
    "        if(predicted == target):\n",
    "            count=count+1\n",
    "    return str(count/len(target_vector)*100)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "UgNa4-pMjFl2",
    "outputId": "5ed4d819-ebbd-48d3-9f99-99f2e5edf525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen Validation Accuracy: 75.27964205816555\n",
      "Seen Dataset time to infer in sec: 329.510728597641\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Seen Validation Accuracy: \" + \n",
    "      getValidationAccuracy(validation_seen_target_vector,seenValidationDict,seenBayesianModel)) \n",
    "end = time.time()\n",
    "print(\"Seen Dataset time to infer in sec: \" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ShVr91FpjMBd",
    "outputId": "d7f80796-59e1-49d3-f22e-59d17096037f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled Validation Accuracy: 64.75190839694656\n",
      "Shuffled Dataset time to infer in sec: 1930.1885719299316\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Shuffled Validation Accuracy: \" + \n",
    "      getValidationAccuracy(validation_shuffled_target_vector,shuffledValidationDict,shuffledBayesianModel)) \n",
    "end = time.time()\n",
    "print(\"Shuffled Dataset time to infer in sec: \" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Tr7SIyxKjMzg",
    "outputId": "3443d1d3-25d2-4aa5-9175-88459200514c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen Validation Accuracy: 56.82038498822878\n",
      "Unseen Dataset time to infer in sec: 2665.3244273662567\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Unseen Validation Accuracy: \" + \n",
    "      getValidationAccuracy(validation_unseen_target_vector,unseenValidationDict,unseenBayesianModel)) \n",
    "end = time.time()\n",
    "print(\"Unseen Dataset time to infer in sec: \" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KthPgdppjyu9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Project2_Task2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
